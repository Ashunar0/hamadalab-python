{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba15887",
   "metadata": {},
   "source": [
    "# XGBoost単体モデル vs アンサンブル 比較\n",
    "**目的**: XGBoost単体（95.2%）がアンサンブル（93.9%）より高精度なため、詳細比較を行う。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4976853c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries loaded.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96520dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データ読み込み\n",
    "train_data = pd.read_csv('train_pitcher_v2.csv')\n",
    "test_data = pd.read_csv('test_pitcher_v2.csv')\n",
    "\n",
    "# 特徴量\n",
    "all_features = [\n",
    "    'release_speed', 'release_spin_rate', 'spin_axis', 'pfx_x', 'pfx_z',\n",
    "    'release_pos_x', 'release_pos_z',\n",
    "    'normalized_spin_axis', 'movement_angle', 'abs_horizontal_movement',\n",
    "    'movement_magnitude', 'spin_efficiency', 'speed_spin_ratio',\n",
    "    'horizontal_vertical_ratio', 'release_position_magnitude',\n",
    "    'vertical_rise', 'sink_rate', 'spin_axis_deviation_from_fastball',\n",
    "    'velocity_times_pfx_z', 'velocity_abs_pfx_x_ratio', 'pfx_z_minus_abs_pfx_x',\n",
    "    'speed_diff', 'spin_diff', 'pfx_x_diff', 'pfx_z_diff'\n",
    "]\n",
    "\n",
    "available_features = [f for f in all_features if f in train_data.columns]\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(train_data['pitch_type'])\n",
    "y_test = le.transform(test_data['pitch_type'])\n",
    "X_train = train_data[available_features]\n",
    "X_test = test_data[available_features]\n",
    "\n",
    "print(f\"Features: {len(available_features)}\")\n",
    "print(f\"Train: {X_train.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09a908e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最適化パラメータでモデル学習\n",
    "print(\"Training models...\")\n",
    "\n",
    "# XGBoost\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    n_estimators=200, max_depth=10, learning_rate=0.1, min_child_weight=0.5,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "xgb_model.fit(X_train, y_train)\n",
    "xgb_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# LightGBM\n",
    "lgb_model = lgb.LGBMClassifier(\n",
    "    n_estimators=100, max_depth=7, learning_rate=0.05,\n",
    "    random_state=42, n_jobs=-1, verbose=-1\n",
    ")\n",
    "lgb_model.fit(X_train, y_train)\n",
    "lgb_pred = lgb_model.predict(X_test)\n",
    "\n",
    "# RandomForest\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=None, min_samples_leaf=1,\n",
    "    random_state=42, n_jobs=-1\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "rf_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Ensemble\n",
    "p_ensemble = (xgb_model.predict_proba(X_test) + lgb_model.predict_proba(X_test) + rf_model.predict_proba(X_test)) / 3\n",
    "ensemble_pred = np.argmax(p_ensemble, axis=1)\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4203d58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 詳細比較 ===\n",
    "print(\"=\"*70)\n",
    "print(\"=== XGBoost単体 vs アンサンブル 詳細比較 ===\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "models = {\n",
    "    'XGBoost': xgb_pred,\n",
    "    'LightGBM': lgb_pred,\n",
    "    'RandomForest': rf_pred,\n",
    "    'Ensemble': ensemble_pred\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, pred in models.items():\n",
    "    acc = accuracy_score(y_test, pred)\n",
    "    f1 = f1_score(y_test, pred, average='weighted')\n",
    "    report = classification_report(y_test, pred, output_dict=True, target_names=le.classes_)\n",
    "    fc_recall = report['FC']['recall']\n",
    "    si_recall = report['SI']['recall']\n",
    "    sl_recall = report['SL']['recall']\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': acc,\n",
    "        'F1': f1,\n",
    "        'FC Recall': fc_recall,\n",
    "        'SI Recall': si_recall,\n",
    "        'SL Recall': sl_recall\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Best model highlight\n",
    "best_acc = results_df.loc[results_df['Accuracy'].idxmax()]\n",
    "print(f\"\\n★ 最高精度: {best_acc['Model']} (Accuracy: {best_acc['Accuracy']:.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505a5c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === XGBoost単体の詳細レポート ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"=== XGBoost単体モデル 詳細レポート ===\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(classification_report(y_test, xgb_pred, target_names=le.classes_))\n",
    "\n",
    "# FC/SL誤分類\n",
    "xgb_results = test_data.copy()\n",
    "xgb_results['true'] = le.inverse_transform(y_test)\n",
    "xgb_results['pred'] = le.inverse_transform(xgb_pred)\n",
    "\n",
    "fc_data = xgb_results[xgb_results['true'] == 'FC']\n",
    "fc_to_sl = len(fc_data[fc_data['pred'] == 'SL'])\n",
    "print(f\"\\nFC → SL 誤分類: {fc_to_sl} / {len(fc_data)} ({fc_to_sl/len(fc_data)*100:.1f}%)\")\n",
    "\n",
    "sl_data = xgb_results[xgb_results['true'] == 'SL']\n",
    "sl_to_fc = len(sl_data[sl_data['pred'] == 'FC'])\n",
    "print(f\"SL → FC 誤分類: {sl_to_fc} / {len(sl_data)} ({sl_to_fc/len(sl_data)*100:.1f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9456349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 混同行列比較 ===\n",
    "fig, axes = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# XGBoost\n",
    "cm_xgb = confusion_matrix(y_test, xgb_pred)\n",
    "cm_xgb_norm = cm_xgb.astype('float') / cm_xgb.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_xgb_norm, annot=True, fmt='.2f', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_, ax=axes[0])\n",
    "axes[0].set_title('XGBoost単体（Recall）', fontsize=14)\n",
    "axes[0].set_xlabel('予測')\n",
    "axes[0].set_ylabel('真')\n",
    "\n",
    "# Ensemble\n",
    "cm_ens = confusion_matrix(y_test, ensemble_pred)\n",
    "cm_ens_norm = cm_ens.astype('float') / cm_ens.sum(axis=1)[:, np.newaxis]\n",
    "sns.heatmap(cm_ens_norm, annot=True, fmt='.2f', cmap='Blues', \n",
    "            xticklabels=le.classes_, yticklabels=le.classes_, ax=axes[1])\n",
    "axes[1].set_title('アンサンブル（Recall）', fontsize=14)\n",
    "axes[1].set_xlabel('予測')\n",
    "axes[1].set_ylabel('真')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702fc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === 結論 ===\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"=== 結論 ===\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "xgb_acc = results_df[results_df['Model']=='XGBoost']['Accuracy'].values[0]\n",
    "ens_acc = results_df[results_df['Model']=='Ensemble']['Accuracy'].values[0]\n",
    "xgb_fc = results_df[results_df['Model']=='XGBoost']['FC Recall'].values[0]\n",
    "ens_fc = results_df[results_df['Model']=='Ensemble']['FC Recall'].values[0]\n",
    "\n",
    "print(f\"\\nXGBoost単体 vs アンサンブル:\")\n",
    "print(f\"  Accuracy: {xgb_acc:.4f} vs {ens_acc:.4f} (差: {xgb_acc - ens_acc:+.4f})\")\n",
    "print(f\"  FC Recall: {xgb_fc:.4f} vs {ens_fc:.4f} (差: {xgb_fc - ens_fc:+.4f})\")\n",
    "\n",
    "if xgb_acc > ens_acc:\n",
    "    print(f\"\\n★ XGBoost単体を最終モデルとして採用することを推奨\")\n",
    "else:\n",
    "    print(f\"\\n★ アンサンブルを最終モデルとして採用することを推奨\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
