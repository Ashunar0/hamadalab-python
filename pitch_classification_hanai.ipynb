{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 投球タイプ分類器（Pitch Identification Model）\n",
        "\n",
        "本プロジェクトは、pybaseballライブラリを用いてMLBのStatcastデータを取得し、投球の物理的な特徴量（球速、回転、変化量など）からその球種（pitch_type）を分類する機械学習モデルを構築します。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 目次\n",
        "0. ライブラリ・データ読み込み\n",
        "1. データの概観・分析・前処理\n",
        "2. ベースラインモデルの構築\n",
        "3. 特徴量エンジニアリング\n",
        "4. 様々なモデルの構築・調整\n",
        "5. モデルのアンサンブリング\n",
        "6. 予測の出力・評価\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0. ライブラリ・データ読み込み\n",
        "\n",
        "まず初めに使用するライブラリを読み込みます。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mJupyter cannot be started. Error attempting to locate Jupyter: Running cells with 'Python 3.9.6' requires the notebook package.\n",
            "\u001b[1;31mInstall 'jupyter and notebook' into the Python environment. \n",
            "\u001b[1;31mCommand: 'python -m pip install jupyter notebook -U\n",
            "\u001b[1;31mor\n",
            "\u001b[1;31mconda install jupyter notebook -U'\n",
            "\u001b[1;31mClick <a href='https://aka.ms/installJupyterForVSCode'>here</a> for more info."
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# データ取得ライブラリ\n",
        "from pybaseball import statcast\n",
        "\n",
        "# 機械学習モデル\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 警告非表示\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "次にpybaseball.statcast()を用いて、特定の期間の投球データを取得します。\n",
        "\n",
        "注意：全期間を取得するとデータ量が膨大になるため、期間を絞るか、特定の投手でテストすることを推奨します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 例：2023年シーズンのデータを取得\n",
        "# (注意：全期間を取得するとデータ量が膨大になるため、期間を絞るか、特定の投手でテストする)\n",
        "print(\"Fetching Statcast data...\")\n",
        "data = statcast(start_dt='2023-04-01', end_dt='2023-10-01')\n",
        "print(\"Data fetched.\")\n",
        "print(f\"Data shape: {data.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. データの概観・分析・前処理\n",
        "\n",
        "### 1.1 データの概観\n",
        "\n",
        "データのサイズを確認します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f'データ数は{data.shape[0]}、変数は{data.shape[1]}種類です。')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの最初の数行を確認\n",
        "data.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 変数名の一覧を確認\n",
        "data.columns.tolist()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2 データの分析（EDA）\n",
        "\n",
        "探索的データ分析（EDA）を行います。まず、必要な特徴量とターゲットが存在することを確認します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 必要な特徴量の確認\n",
        "required_features = ['release_speed', 'release_spin_rate', 'spin_axis', \n",
        "                     'pfx_x', 'pfx_z', 'release_pos_x', 'release_pos_z', 'pitch_type']\n",
        "\n",
        "# 存在する特徴量を確認\n",
        "available_features = [feat for feat in required_features if feat in data.columns]\n",
        "missing_features = [feat for feat in required_features if feat not in data.columns]\n",
        "\n",
        "print(\"利用可能な特徴量:\", available_features)\n",
        "print(\"欠損している特徴量:\", missing_features)\n",
        "\n",
        "# 利用可能な特徴量のみを使用\n",
        "if len(missing_features) > 0:\n",
        "    print(f\"\\n警告: 以下の特徴量がデータに存在しません: {missing_features}\")\n",
        "    print(\"利用可能な特徴量のみを使用します。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 欠損値の確認（利用可能な特徴量のみ）\n",
        "print(\"欠損値の確認:\")\n",
        "if len(available_features) > 0:\n",
        "    print(data[available_features].isnull().sum())\n",
        "else:\n",
        "    print(\"利用可能な特徴量がありません。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ターゲット（pitch_type）の分析\n",
        "if 'pitch_type' in data.columns:\n",
        "    print(\"球種の内訳:\")\n",
        "    print(data['pitch_type'].value_counts())\n",
        "    print(\"\\n球種の割合:\")\n",
        "    print(data['pitch_type'].value_counts(normalize=True))\n",
        "else:\n",
        "    print(\"エラー: 'pitch_type'列がデータに存在しません。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 球種ごとの分布を可視化（バイオリン図）\n",
        "# 利用可能な特徴量のみを使用\n",
        "plot_features = []\n",
        "if 'release_speed' in data.columns:\n",
        "    plot_features.append(('release_speed', 'Release Speed'))\n",
        "if 'pfx_x' in data.columns:\n",
        "    plot_features.append(('pfx_x', 'Horizontal Movement (pfx_x)'))\n",
        "if 'pfx_z' in data.columns:\n",
        "    plot_features.append(('pfx_z', 'Vertical Movement (pfx_z)'))\n",
        "if 'release_spin_rate' in data.columns:\n",
        "    plot_features.append(('release_spin_rate', 'Spin Rate'))\n",
        "\n",
        "if len(plot_features) > 0 and 'pitch_type' in data.columns:\n",
        "    # データのコピーを作成してインデックスをリセット（重複インデックスの問題を回避）\n",
        "    plot_data = data[['pitch_type'] + [feat for feat, _ in plot_features]].copy().reset_index(drop=True)\n",
        "    \n",
        "    n_plots = min(len(plot_features), 4)\n",
        "    n_cols = 2\n",
        "    n_rows = (n_plots + 1) // 2\n",
        "    f, ax = plt.subplots(n_rows, n_cols, figsize=(18, 6*n_rows), facecolor='gray')\n",
        "    if n_rows == 1:\n",
        "        ax = ax.reshape(1, -1)\n",
        "    \n",
        "    for idx, (feat, title) in enumerate(plot_features[:4]):\n",
        "        row = idx // n_cols\n",
        "        col = idx % n_cols\n",
        "        sns.violinplot(x=\"pitch_type\", y=feat, data=plot_data, ax=ax[row, col])\n",
        "        ax[row, col].set_title(f'Pitch Type vs {title}')\n",
        "        ax[row, col].tick_params(axis='x', rotation=45)\n",
        "    \n",
        "    # 余ったサブプロットを非表示\n",
        "    for idx in range(n_plots, n_rows * n_cols):\n",
        "        row = idx // n_cols\n",
        "        col = idx % n_cols\n",
        "        ax[row, col].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"可視化に必要な特徴量が不足しています。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 相関行列のヒートマップ\n",
        "numeric_features = ['release_speed', 'release_spin_rate', 'spin_axis', \n",
        "                    'pfx_x', 'pfx_z', 'release_pos_x', 'release_pos_z']\n",
        "# 存在する特徴量のみを使用\n",
        "numeric_features_available = [feat for feat in numeric_features if feat in data.columns]\n",
        "\n",
        "if len(numeric_features_available) > 0:\n",
        "    df_numeric = data[numeric_features_available].select_dtypes(include=['number'])\n",
        "    if len(df_numeric.columns) > 0:\n",
        "        sns.heatmap(df_numeric.corr(), annot=True, cmap='bwr', linewidths=0.2, fmt='.2f')\n",
        "        fig = plt.gcf()\n",
        "        fig.set_size_inches(10, 8)\n",
        "        plt.title('Correlation Matrix of Numeric Features')\n",
        "        plt.show()\n",
        "    else:\n",
        "        print(\"数値型の特徴量がありません。\")\n",
        "else:\n",
        "    print(\"相関行列を作成するための特徴量が不足しています。\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.3 データの前処理\n",
        "\n",
        "機械学習モデルが学習できるようにデータの前処理を行います。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データのコピーを作成\n",
        "df = data.copy()\n",
        "\n",
        "# 必要な特徴量を選択（存在する特徴量のみ）\n",
        "feature_cols = ['release_speed', 'release_spin_rate', 'spin_axis', \n",
        "                'pfx_x', 'pfx_z', 'release_pos_x', 'release_pos_z']\n",
        "feature_cols = [feat for feat in feature_cols if feat in df.columns]\n",
        "\n",
        "if len(feature_cols) == 0:\n",
        "    raise ValueError(\"必要な特徴量がデータに存在しません。\")\n",
        "\n",
        "print(f\"使用する特徴量: {feature_cols}\")\n",
        "\n",
        "# 欠損値の処理：欠損が多い行を削除\n",
        "print(\"前処理前のデータ数:\", len(df))\n",
        "if 'pitch_type' in df.columns:\n",
        "    df = df.dropna(subset=feature_cols + ['pitch_type'])\n",
        "else:\n",
        "    raise ValueError(\"'pitch_type'列がデータに存在しません。\")\n",
        "print(\"前処理後のデータ数:\", len(df))\n",
        "\n",
        "# 欠損値の確認\n",
        "print(\"\\n欠損値の確認:\")\n",
        "print(df[feature_cols + ['pitch_type']].isnull().sum())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 投球数が少ない球種を除外または「Others」にまとめる\n",
        "pitch_counts = df['pitch_type'].value_counts()\n",
        "print(\"各球種の投球数:\")\n",
        "print(pitch_counts)\n",
        "\n",
        "# 投球数が100未満の球種を「Others」にまとめる（閾値は調整可能）\n",
        "min_pitches = 100\n",
        "rare_pitches = pitch_counts[pitch_counts < min_pitches].index.tolist()\n",
        "print(f\"\\n投球数が{min_pitches}未満の球種（Othersにまとめる）: {rare_pitches}\")\n",
        "\n",
        "if len(rare_pitches) > 0:\n",
        "    df['pitch_type'] = df['pitch_type'].replace(rare_pitches, 'Others')\n",
        "    print(\"\\n処理後の球種の内訳:\")\n",
        "    print(df['pitch_type'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量（X）とターゲット（Y）を抽出\n",
        "X = df[feature_cols].values\n",
        "y = df['pitch_type'].values\n",
        "\n",
        "# ターゲットのエンコーディング（LabelEncoder）\n",
        "le = LabelEncoder()\n",
        "y_encoded = le.fit_transform(y)\n",
        "\n",
        "print(\"特徴量の形状:\", X.shape)\n",
        "print(\"ターゲットの形状:\", y_encoded.shape)\n",
        "print(\"球種のクラス数:\", len(le.classes_))\n",
        "print(\"球種のクラス:\", le.classes_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# データの分割（訓練データと検証データ）\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y_encoded)\n",
        "\n",
        "print(f\"訓練データ数: {X_train.shape[0]}\")\n",
        "print(f\"検証データ数: {X_valid.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. ベースラインモデルの構築\n",
        "\n",
        "まずは単純なモデルで、現状のデータと前処理でどの程度の精度が出るかを確認します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ベースラインモデル：全特徴量を使用\n",
        "rfc_baseline = RandomForestClassifier(max_depth=10, min_samples_leaf=1, n_estimators=100, n_jobs=-1, random_state=42)\n",
        "rfc_baseline.fit(X_train, y_train)\n",
        "\n",
        "print('ベースラインモデル（全特徴量）')\n",
        "print('Train Score: {}'.format(round(rfc_baseline.score(X_train, y_train), 3)))\n",
        "print('Valid Score: {}'.format(round(rfc_baseline.score(X_valid, y_valid), 3)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 特徴量エンジニアリング\n",
        "\n",
        "ドメイン知識（野球の知識）に基づき、よりモデルの精度向上に寄与する特徴量を作成します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量エンジニアリング用のデータフレームを作成\n",
        "df_fe = df.copy()\n",
        "\n",
        "# 1. 回転軸の変換（spin_axisは循環的な特徴量なので、sinとcosに変換）\n",
        "if 'spin_axis' in df_fe.columns:\n",
        "    df_fe['spin_axis_sin'] = np.sin(np.radians(df_fe['spin_axis']))\n",
        "    df_fe['spin_axis_cos'] = np.cos(np.radians(df_fe['spin_axis']))\n",
        "    print(\"spin_axis_sin と spin_axis_cos を作成しました。\")\n",
        "else:\n",
        "    print(\"警告: 'spin_axis'が存在しないため、spin_axis_sin と spin_axis_cos をスキップします。\")\n",
        "\n",
        "# 2. 変化量の合成（水平変化量と垂直変化量から総変化量を計算）\n",
        "if 'pfx_x' in df_fe.columns and 'pfx_z' in df_fe.columns:\n",
        "    df_fe['total_movement'] = np.sqrt(df_fe['pfx_x']**2 + df_fe['pfx_z']**2)\n",
        "    print(\"total_movement を作成しました。\")\n",
        "else:\n",
        "    print(\"警告: 'pfx_x' または 'pfx_z' が存在しないため、total_movement をスキップします。\")\n",
        "\n",
        "# 3. スピン効率（推定）：球速に対する回転数の比率\n",
        "if 'release_spin_rate' in df_fe.columns and 'release_speed' in df_fe.columns:\n",
        "    # ゼロ除算を防ぐため、release_speedが0の場合はNaNにする\n",
        "    df_fe['spin_per_mph'] = df_fe['release_spin_rate'] / df_fe['release_speed'].replace(0, np.nan)\n",
        "    print(\"spin_per_mph を作成しました。\")\n",
        "else:\n",
        "    print(\"警告: 'release_spin_rate' または 'release_speed' が存在しないため、spin_per_mph をスキップします。\")\n",
        "\n",
        "# 新しい特徴量を確認\n",
        "new_feature_list = []\n",
        "if 'spin_axis_sin' in df_fe.columns:\n",
        "    new_feature_list.append('spin_axis_sin')\n",
        "if 'spin_axis_cos' in df_fe.columns:\n",
        "    new_feature_list.append('spin_axis_cos')\n",
        "if 'total_movement' in df_fe.columns:\n",
        "    new_feature_list.append('total_movement')\n",
        "if 'spin_per_mph' in df_fe.columns:\n",
        "    new_feature_list.append('spin_per_mph')\n",
        "\n",
        "if len(new_feature_list) > 0:\n",
        "    print(\"\\n新しく作成した特徴量:\")\n",
        "    print(df_fe[new_feature_list].head())\n",
        "    print(\"\\n欠損値の確認:\")\n",
        "    print(df_fe[new_feature_list].isnull().sum())\n",
        "else:\n",
        "    print(\"\\n新しく作成された特徴量はありません。\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量エンジニアリング後の特徴量リスト\n",
        "new_features = ['spin_axis_sin', 'spin_axis_cos', 'total_movement', 'spin_per_mph']\n",
        "feature_cols_fe = feature_cols + [feat for feat in new_features if feat in df_fe.columns]\n",
        "\n",
        "# 欠損値の処理\n",
        "df_fe = df_fe.dropna(subset=feature_cols_fe + ['pitch_type'])\n",
        "\n",
        "# 特徴量とターゲットを抽出\n",
        "X_fe = df_fe[feature_cols_fe].values\n",
        "y_fe = df_fe['pitch_type'].values\n",
        "\n",
        "# ターゲットのエンコーディング（新しいLabelEncoderを作成してfit_transformを使用）\n",
        "# 特徴量エンジニアリング後のデータでも同じ球種が含まれているはずですが、\n",
        "# 念のため新しいLabelEncoderを使用します\n",
        "le_fe = LabelEncoder()\n",
        "y_fe_encoded = le_fe.fit_transform(y_fe)\n",
        "\n",
        "# データの分割\n",
        "# stratifyを使用するため、インデックスではなく配列を直接分割\n",
        "X_fe_train, X_fe_valid, y_fe_train, y_fe_valid = train_test_split(\n",
        "    X_fe, y_fe_encoded, test_size=0.3, random_state=42, stratify=y_fe_encoded\n",
        ")\n",
        "\n",
        "print(f\"特徴量エンジニアリング後の特徴量数: {len(feature_cols_fe)}\")\n",
        "print(f\"特徴量: {feature_cols_fe}\")\n",
        "print(f\"訓練データ数: {X_fe_train.shape[0]}\")\n",
        "print(f\"検証データ数: {X_fe_valid.shape[0]}\")\n",
        "print(f\"球種のクラス数: {len(le_fe.classes_)}\")\n",
        "print(f\"球種のクラス: {le_fe.classes_}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特徴量エンジニアリング後のベースラインモデル\n",
        "rfc_fe = RandomForestClassifier(max_depth=7, min_samples_leaf=1, n_estimators=100, n_jobs=-1, random_state=42)\n",
        "rfc_fe.fit(X_fe_train, y_fe_train)\n",
        "\n",
        "print('特徴量エンジニアリング後のベースラインモデル')\n",
        "print('Train Score: {}'.format(round(rfc_fe.score(X_fe_train, y_fe_train), 3)))\n",
        "print('Valid Score: {}'.format(round(rfc_fe.score(X_fe_valid, y_fe_valid), 3)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 様々なモデルの構築・調整\n",
        "\n",
        "ベースラインモデルや特徴量エンジニアリングの結果を踏まえ、より強力なモデルを構築・調整します。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# XGBoostモデル\n",
        "xgb_model = xgb.XGBClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "xgb_model.fit(X_fe_train, y_fe_train)\n",
        "\n",
        "print('XGBoostモデル')\n",
        "print('Train Score: {}'.format(round(xgb_model.score(X_fe_train, y_fe_train), 3)))\n",
        "print('Valid Score: {}'.format(round(xgb_model.score(X_fe_valid, y_fe_valid), 3)))\n",
        "print('Valid F1 Score (weighted): {}'.format(round(f1_score(y_fe_valid, xgb_model.predict(X_fe_valid), average='weighted'), 3)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# LightGBMモデル\n",
        "lgb_model = lgb.LGBMClassifier(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42,\n",
        "    n_jobs=-1,\n",
        "    verbose=-1\n",
        ")\n",
        "lgb_model.fit(X_fe_train, y_fe_train)\n",
        "\n",
        "print('LightGBMモデル')\n",
        "print('Train Score: {}'.format(round(lgb_model.score(X_fe_train, y_fe_train), 3)))\n",
        "print('Valid Score: {}'.format(round(lgb_model.score(X_fe_valid, y_fe_valid), 3)))\n",
        "print('Valid F1 Score (weighted): {}'.format(round(f1_score(y_fe_valid, lgb_model.predict(X_fe_valid), average='weighted'), 3)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ハイパーパラメータチューニング（GridSearchCV）- LightGBMの例\n",
        "# 注意：計算時間がかかるため、パラメータの範囲を狭めています\n",
        "param_grid_lgb = {\n",
        "    'max_depth': [5, 7],\n",
        "    'learning_rate': [0.05, 0.1],\n",
        "    'n_estimators': [100, 200]\n",
        "}\n",
        "\n",
        "print(\"GridSearchCVを実行中...（時間がかかる場合があります）\")\n",
        "lgb_gs = GridSearchCV(\n",
        "    lgb.LGBMClassifier(random_state=42, n_jobs=-1, verbose=-1),\n",
        "    param_grid_lgb,\n",
        "    cv=3,  # クロスバリデーションの分割数（計算時間を考慮して3に設定）\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "lgb_gs.fit(X_fe_train, y_fe_train)\n",
        "\n",
        "print('Best Parameters: {}'.format(lgb_gs.best_params_))\n",
        "print('CV Score: {}'.format(round(lgb_gs.best_score_, 3)))\n",
        "print('Valid Score: {}'.format(round(lgb_gs.score(X_fe_valid, y_fe_valid), 3)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. モデルのアンサンブリング\n",
        "\n",
        "複数のモデルを組み合わせて、より頑健なモデルとします。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 各モデルの予測確率を取得\n",
        "rfc_pred_proba = rfc_fe.predict_proba(X_fe_valid)\n",
        "xgb_pred_proba = xgb_model.predict_proba(X_fe_valid)\n",
        "lgb_pred_proba = lgb_model.predict_proba(X_fe_valid)\n",
        "\n",
        "# 予測確率の平均（ブレンディング）\n",
        "ensemble_pred_proba = (rfc_pred_proba + xgb_pred_proba + lgb_pred_proba) / 3\n",
        "ensemble_pred = ensemble_pred_proba.argmax(axis=1)\n",
        "\n",
        "# アンサンブルモデルの評価\n",
        "ensemble_accuracy = accuracy_score(y_fe_valid, ensemble_pred)\n",
        "ensemble_f1 = f1_score(y_fe_valid, ensemble_pred, average='weighted')\n",
        "\n",
        "print('アンサンブルモデル（RandomForest + XGBoost + LightGBM）')\n",
        "print('Valid Accuracy: {}'.format(round(ensemble_accuracy, 3)))\n",
        "print('Valid F1 Score (weighted): {}'.format(round(ensemble_f1, 3)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 予測の出力・評価\n",
        "\n",
        "最終的に構築したモデルを使い、検証データに対して予測を行い、詳細な評価を行います。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 最良モデル（アンサンブルモデル）の予測\n",
        "best_pred = ensemble_pred\n",
        "\n",
        "# Classification Report（適合率、再現率、F1スコア）\n",
        "# 特徴量エンジニアリング後のLabelEncoderを使用\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_fe_valid, best_pred, target_names=le_fe.classes_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 混同行列（Confusion Matrix）\n",
        "cm = confusion_matrix(y_fe_valid, best_pred)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=le_fe.classes_, yticklabels=le_fe.classes_)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance（特徴量重要度）の可視化 - LightGBM\n",
        "lgb.plot_importance(lgb_model, figsize=(10, 8), max_num_features=15)\n",
        "plt.title('LightGBM Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature Importance（特徴量重要度）の可視化 - XGBoost\n",
        "plt.figure(figsize=(10, 8))\n",
        "xgb.plot_importance(xgb_model, max_num_features=15)\n",
        "plt.title('XGBoost Feature Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# RandomForestの特徴量重要度\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': feature_cols_fe,\n",
        "    'importance': rfc_fe.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.barplot(data=feature_importance, x='importance', y='feature')\n",
        "plt.title('RandomForest Feature Importance')\n",
        "plt.xlabel('Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
